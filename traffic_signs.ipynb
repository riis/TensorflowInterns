{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "traffic_signs.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0acoyN-Z9d3G",
        "colab_type": "text"
      },
      "source": [
        "Setup tensorflow object detection dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrT4PqhdrUou",
        "colab_type": "text"
      },
      "source": [
        "Use tensorflow 1.0 since tensorflow 2.0 currently has issues converting to tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0TJGY9YBhUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBnheTb3BpCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhHXnG6ABq0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install Cython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki_5enNCBtLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf1/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Iw74Fp49oXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYRshLW_Bwfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-J0IEX4ByAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tf_slim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjMcbfRCreXe",
        "colab_type": "text"
      },
      "source": [
        "Test to make sure all of the dependencies were installed correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PMivkQ2Bz5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%cd /content/models/research/object_detection/builders/\n",
        "!python model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA0XI830p2or",
        "colab_type": "text"
      },
      "source": [
        "\n",
        " Download the dataset of annotated images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2uMx-S3ti4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc3zUcSbpq8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://cvrr.ucsd.edu/LISA/Datasets/signDatabasePublicFramesOnly.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yBL0gNJqLUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/signDatabasePublicFramesOnly.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iScon4wB34H",
        "colab_type": "text"
      },
      "source": [
        "Generate a tfrecord from the annotated_images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXfSv_mUCAXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import requests\n",
        "import sys\n",
        "import getopt\n",
        "from getopt import GetoptError\n",
        "import traceback\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from collections import namedtuple\n",
        "import requests\n",
        "import tqdm\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "\n",
        "INPUT_FILE = 'allAnnotations.csv'\n",
        "OUTPUT_FILE = 'traffic_signs.tfrecord'\n",
        "\n",
        "def get_num_records(input_file):\n",
        "  num_records = 0\n",
        "  with open(input_file, 'rt') as csv_file:\n",
        "      csv_reader = csv.DictReader(csv_file, delimiter=',')\n",
        "      num_records = len(csv_file.readlines()) - 1\n",
        "  return num_records\n",
        "\n",
        "def create_tfrecord_from_csv(input_file, output_file, split = 0.9):\n",
        "    writer = tf.io.TFRecordWriter(output_file)\n",
        "    validation_record_file = re.sub(\n",
        "      \"\\.tfrecord\",\n",
        "      \"_val.tfrecord\",\n",
        "      output_file\n",
        "    )\n",
        "    validation_writter = tf.io.TFRecordWriter(validation_record_file)\n",
        "    with open(input_file, 'rt') as csv_file:\n",
        "        csv_reader = csv.DictReader(csv_file, delimiter=';')\n",
        "        num_records = get_num_records(input_file)\n",
        "        validation_index = int(num_records * split)\n",
        "        count = 0\n",
        "        file_dict = {}\n",
        "        csv_data = []\n",
        "        labels = []\n",
        "        for row in tqdm.tqdm(csv_reader, total=num_records):\n",
        "            if file_dict.get(row[\"Filename\"]) is None:\n",
        "                file_dict[row[\"Filename\"]] = {\n",
        "                    \"label_names\": [row[\"Annotation tag\"]],\n",
        "                    \"x_minimums\": [int(row[\"Upper left corner X\"])],\n",
        "                    \"y_minimums\":[int(row[\"Upper left corner Y\"])],\n",
        "                    \"x_maximums\":[int(row[\"Lower right corner X\"])],\n",
        "                    \"y_maximums\":[int(row[\"Lower right corner Y\"])]\n",
        "                }\n",
        "            else:\n",
        "                file_dict[row[\"Filename\"]][\"label_names\"].append(row[\"Annotation tag\"])\n",
        "                file_dict[row[\"Filename\"]][\"x_minimums\"].append(int(row[\"Upper left corner X\"]))\n",
        "                file_dict[row[\"Filename\"]][\"y_minimums\"].append(int(row[\"Upper left corner Y\"]))\n",
        "                file_dict[row[\"Filename\"]][\"x_maximums\"].append(int(row[\"Lower right corner X\"]))\n",
        "                file_dict[row[\"Filename\"]][\"y_maximums\"].append(int(row[\"Lower right corner Y\"]))\n",
        "            \n",
        "            if row[\"Annotation tag\"] not in labels:\n",
        "                labels.append(row[\"Annotation tag\"])\n",
        "\n",
        "        for row in tqdm.tqdm(file_dict):\n",
        "            file_name = row.format(count=count).encode('utf8')\n",
        "            with tf.io.gfile.GFile(file_name, 'rb') as f:\n",
        "                image_data = f.read()\n",
        "\n",
        "            image = Image.open(file_name)\n",
        "            width, height = image.size\n",
        "            for i in range(0, len(file_dict[row]['x_minimums'])):\n",
        "                file_dict[row]['x_minimums'][i] = float(file_dict[row]['x_minimums'][i]) / float(width)\n",
        "                file_dict[row]['x_maximums'][i] = float(file_dict[row]['x_maximums'][i]) / float(width)\n",
        "                file_dict[row]['y_minimums'][i] = float(file_dict[row]['y_minimums'][i]) / float(height)\n",
        "                file_dict[row]['y_maximums'][i] = float(file_dict[row]['y_maximums'][i]) / float(height)\n",
        "\n",
        "            class_indexes = [] \n",
        "            for i in range(0, len(file_dict[row]['label_names'])):\n",
        "                label = file_dict[row]['label_names'][i]\n",
        "                class_indexes.append(labels.index(label) + 1)\n",
        "                file_dict[row]['label_names'][i] = file_dict[row]['label_names'][i].encode('utf8')\n",
        "\n",
        "            tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                'image/height': dataset_util.int64_feature(int(height)),\n",
        "                'image/width': dataset_util.int64_feature(int(width)),\n",
        "                'image/filename': dataset_util.bytes_feature(file_name),\n",
        "                'image/source_id': dataset_util.bytes_feature(file_name),\n",
        "                'image/encoded': dataset_util.bytes_feature(image_data),\n",
        "                'image/format': dataset_util.bytes_feature(b'png'),\n",
        "                'image/object/bbox/xmin': dataset_util.float_list_feature(file_dict[row]['x_minimums']),\n",
        "                'image/object/bbox/xmax': dataset_util.float_list_feature(file_dict[row]['x_maximums']),\n",
        "                'image/object/bbox/ymin': dataset_util.float_list_feature(file_dict[row]['y_minimums']),\n",
        "                'image/object/bbox/ymax': dataset_util.float_list_feature(file_dict[row]['y_maximums']),\n",
        "                'image/object/class/text': dataset_util.bytes_list_feature(file_dict[row][\"label_names\"]),\n",
        "                'image/object/class/label': dataset_util.int64_list_feature(class_indexes),\n",
        "            }))\n",
        "            \n",
        "            if(count >= validation_index):\n",
        "                validation_writter.write(tf_example.SerializeToString())\n",
        "            else:\n",
        "                writer.write(tf_example.SerializeToString())\n",
        "            count += 1\n",
        "        create_pbtxt_file(labels)\n",
        "        writer.close()\n",
        "        validation_writter.close()\n",
        " \n",
        "def create_pbtxt_file(labels):\n",
        "  with open('label_map.pbtxt', 'wt') as label_file:\n",
        "    i = 1\n",
        "    for label in labels:\n",
        "      item_str = \"\\tid: {id}\\n\\tname: '{name}'\\n\".format(id=i, name=label)\n",
        "      item_str = \"item{\\n\" + item_str + \"}\"\n",
        "      if (i != len(labels)):\n",
        "        item_str += \",\\n\"\n",
        "      else:\n",
        "        item_str += \"\\n\"\n",
        "      label_file.write(\n",
        "          item_str\n",
        "      )\n",
        "      i +=1\n",
        "\n",
        "create_tfrecord_from_csv(INPUT_FILE, OUTPUT_FILE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL4UVmFTrnAr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYd__rMqAcKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_record_fname = '/content/traffic_signs_val.tfrecord'\n",
        "train_record_fname = '/content/traffic_signs.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC3DSYmrIimY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=100, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6kNTa7IXXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download base training configuration file\n",
        "model_name = 'ssd_mobilenet_v3_small_coco_2020_01_14'\n",
        "download_config = 'http://download.tensorflow.org/models/object_detection/{model_name}.tar.gz'.format(model_name=model_name)\n",
        "!wget {download_config}\n",
        "!tar -zxvf { model_name + '.tar.gz'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GJ-BAtXKV2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare\n",
        "pipeline_fname = '/content/' + model_name + '/pipeline.config'\n",
        "fine_tune_checkpoint = '/content/' + model_name + '/model.ckpt'\n",
        "batch_size = 64\n",
        "num_steps = 2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dva1-M4vKXuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "\n",
        "import re\n",
        "\n",
        "%cd {'/content/' + model_name + '/'}\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline.config', 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        'input_path: \"PATH_TO_BE_CONFIGURED\\/.*_train.*\"', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        'input_path: \"PATH_TO_BE_CONFIGURED\\/.*_val.*\"', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "     #fine-tune checkpoint type\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "    \n",
        "    s = re.sub(\n",
        "        'learning_rate_base: \\d\\.\\d*', 'learning_rate_base: {}'.format(0.001), s)\n",
        "    s = re.sub(\n",
        "        'warmup_learning_rate: \\d\\.\\d*', 'warmup_learning_rate: {}'.format(0.001), s)\n",
        "    f.write(s)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrXDxRlmKftQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWrMoCOuKf4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/models/research/object_detection/legacy/train.py /content/train.py\n",
        "%cd /content/\n",
        "!python /content/train.py --logtostderr --train_dir=training/ --pipeline_config_path={pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfNBrsQCexYM",
        "colab_type": "text"
      },
      "source": [
        "Exporting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LTZ6johegUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "!python3 export_inference_graph.py --input_type image_tensor --pipeline_config_path {pipeline_fname} --trained_checkpoint_prefix /content/training/model.ckpt-2000 --output_directory /content/trained_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MCSXB7PfK0d",
        "colab_type": "text"
      },
      "source": [
        "Testing the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0cPd9PrfM1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "\n",
        "### Model preparation variable\n",
        "MODEL_NAME = '/content/trained_model'\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS = '/content/label_map.pbtxt'\n",
        "\n",
        "\n",
        "\n",
        "### Load a (frozen) Tensorflow model into memory.\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "###Loading label map\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "### Load image into numpy function\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "    \n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        \n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: image})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.int64)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "image_path = '/content/vid0/stop_1323804419.avi_image32.png'\n",
        "image = Image.open(image_path)\n",
        "# the array based representation of the image will be used later in order to prepare the\n",
        "# result image with boxes and labels on it.\n",
        "image_np = load_image_into_numpy_array(image)\n",
        "# Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "# Actual detection.\n",
        "output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
        "print(output_dict)\n",
        "# Visualization of the results of a detection.\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks'),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=1)\n",
        "display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RWLhhpSlCxg",
        "colab_type": "text"
      },
      "source": [
        "Convert to tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DR2zyi0lCEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "--pipeline_config_path=/content/trained_model/pipeline.config \\\n",
        "--trained_checkpoint_prefix=/content/trained_model/model.ckpt \\\n",
        "--output_directory=/content/tflite \\\n",
        "--add_postprocessing_op=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxvDALOFlQC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install curl gnupg\n",
        "!curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor > bazel.gpg\n",
        "!sudo mv bazel.gpg /etc/apt/trusted.gpg.d/\n",
        "!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n",
        "!sudo apt update && sudo apt install bazel\n",
        "!sudo apt install bazel-3.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WELqNZJtlTM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "!git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvwsegQ9lWyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/tensorflow/\n",
        "!bazel run -c opt tensorflow/lite/toco:toco -- \\\n",
        "--input_file=/content/tflite/tflite_graph.pb \\\n",
        "--output_file=/content/tflite/detect.tflite \\\n",
        "--input_shapes=1,320,320,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\n",
        "--inference_type=FLOAT \\\n",
        "--mean_values=128 \\\n",
        "--std_values=128 \\\n",
        "--change_concat_input_ranges=false \\\n",
        "--allow_custom_ops"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}